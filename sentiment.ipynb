{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "This notebook performs sentiment analysis on a dataset of tweets with different Neural Nets using Tensorflow / Keras."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "source": [
    "# Data\n",
    "\n",
    "Load the data in with pandas. The important columns are:\n",
    "- `text` - the tweet body\n",
    "- `airline_sentiment` - the label. Can be `positive`, `negative`, or `neutral`.\n",
    "- `airline_sentiment_confidence` - value 0-1 giving the confidence of the label."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_full_data(filename=\"Tweets.csv\"):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df[['text', 'airline_sentiment', 'airline_sentiment_confidence']]\n",
    "    return df\n",
    "\n",
    "def clean_text(input):\n",
    "    words = input.split()\n",
    "    words = [w for w in words if not w.startswith('@')] #removes any mentions\n",
    "    return ' '.join(words)\n",
    "\n",
    "def transform_sentiment(s):\n",
    "    smap = {'neutral':0, 'positive':1, 'negative':2}\n",
    "    if s in smap:\n",
    "        return smap[s]\n",
    "    print(\"Unknown sentiment \" + s)\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_full_data()\n",
    "df.text = df.text.apply(clean_text)\n",
    "df.airline_sentiment = df.airline_sentiment.apply(transform_sentiment)"
   ]
  },
  {
   "source": [
    "Let's check the distribution across the different labels."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   text  airline_sentiment_confidence\n",
       "airline_sentiment                                    \n",
       "0                  3099                          3099\n",
       "1                  2363                          2363\n",
       "2                  9178                          9178"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>airline_sentiment_confidence</th>\n    </tr>\n    <tr>\n      <th>airline_sentiment</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3099</td>\n      <td>3099</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2363</td>\n      <td>2363</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9178</td>\n      <td>9178</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.groupby(df['airline_sentiment']).count()"
   ]
  },
  {
   "source": [
    "`airline_sentiment==2` (i.e. negative) is represented much more than `0` (neutral) or `1` (positive).\n",
    "\n",
    "Let's just make them all equal (grab the min, or `2,363` for each)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_per_label = min(df.groupby(['airline_sentiment']).count().text)\n",
    "\n",
    "neu = df[df['airline_sentiment']==0].sort_values(by=['airline_sentiment_confidence'], ascending=False).head(num_per_label)\n",
    "pos = df[df['airline_sentiment']==1].sort_values(by=['airline_sentiment_confidence'], ascending=False).head(num_per_label)\n",
    "neg = df[df['airline_sentiment']==2].sort_values(by=['airline_sentiment_confidence'], ascending=False).head(num_per_label)\n",
    "\n",
    "df = pd.concat([pos, neu, neg])"
   ]
  },
  {
   "source": [
    "# Word Embedding\n",
    "\n",
    "Our input is a string of words, but to use as input, we need to create a word embedding of some sort.\n",
    "\n",
    "Here we'll use Keras' built-in Tokenizer to map each word to an int, and then an Embedding layer to create the vectors.\n",
    "\n",
    "First, let's see how big we should make our Tokenizer dictionary."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num words: 17646\nNum words that appear more than once: 5874\n"
     ]
    }
   ],
   "source": [
    "words = defaultdict(int)\n",
    "for t in df.text:\n",
    "    for w in t.split():\n",
    "        words[w]+=1\n",
    "print(f\"Num words: {len(words)}\")\n",
    "print(f\"Num words that appear more than once: {len([w for w in words if words[w]>1])}\")"
   ]
  },
  {
   "source": [
    "There are only `5,874` words that appear more than once. Let's use a bit more than that as our dictionary size."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_size = 6000"
   ]
  },
  {
   "source": [
    "Now we can create our Tokenizer."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer(num_words=dict_size)\n",
    "tk.fit_on_texts(df.text)"
   ]
  },
  {
   "source": [
    "You can see below that many of the most common words are not very informative (e.g. 'to', 'the', 'a'). These are called \"stop words,\" and using a stop word dictionary (e.g. from nltk) you can remove these. I didn't here, but you definitely can."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('to', 3858),\n",
       " ('the', 2691),\n",
       " ('i', 2380),\n",
       " ('you', 2029),\n",
       " ('a', 1934),\n",
       " ('for', 1907),\n",
       " ('on', 1696),\n",
       " ('flight', 1681),\n",
       " ('and', 1548),\n",
       " ('my', 1390)]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "collections.Counter(tk.word_counts).most_common(10)"
   ]
  },
  {
   "source": [
    "# Input Preparation\n",
    "\n",
    "Now let's prepare our inputs for going into the model.\n",
    "\n",
    "For text, we need to use our Tokenizer to turn the words into sequences, then pad the sequences to the same length."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tk.texts_to_sequences(df.text)\n",
    "X = pad_sequences(X)\n",
    "INPUT_LEN = len(X[0])"
   ]
  },
  {
   "source": [
    "For the labels, we need to convert from an int (0-2) to a one-hot encoding (`[1,0,0]` or `[0,1,0]` or `[0,0,1]`)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tf.keras.utils.to_categorical(df.airline_sentiment)"
   ]
  },
  {
   "source": [
    "# Model\n",
    "\n",
    "Here we actually define the model.\n",
    "\n",
    "The input shape to the Embedding layer is [None, 33], where the None depends on the batch size (i.e. how many inputs you give at once). The type of each of those input is an int between `0` and `tk.num_words-1`. The Embedding layer translates each int into a size 64 vector.\n",
    "\n",
    "Then an LSTM layer with 64 units is fed each word vector.\n",
    "\n",
    "The final output of the LSTM layer is input into a Densely connected layer of output size 32, which goes to another Dense layer of output size 3.\n",
    "\n",
    "The 3 outputs are run through a softmax layer to get the probability of each answer (neutral vs positive vs negative).\n",
    "\n",
    "Since this is a multi-class classification problem, I use categorical cross-entropy. Adam optimizer is pretty standard, and categorical accuracy is a way to test how often predictions match the one-hot labels."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.Embedding(input_dim=tk.num_words, output_dim=64, input_length=INPUT_LEN))\n",
    "    model.add(layers.LSTM(64))\n",
    "    model.add(layers.Dense(32))\n",
    "    model.add(layers.Dense(3))\n",
    "    model.add(layers.Softmax())\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_6 (Embedding)      (None, 33, 64)            384000    \n_________________________________________________________________\nlstm_6 (LSTM)                (None, 64)                33024     \n_________________________________________________________________\ndense_12 (Dense)             (None, 32)                2080      \n_________________________________________________________________\ndense_13 (Dense)             (None, 3)                 99        \n_________________________________________________________________\nsoftmax_6 (Softmax)          (None, 3)                 0         \n=================================================================\nTotal params: 419,203\nTrainable params: 419,203\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gen_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/25\n",
      "40/40 [==============================] - 2s 23ms/step - loss: 1.0158 - categorical_accuracy: 0.4782 - val_loss: 0.8750 - val_categorical_accuracy: 0.8028\n",
      "Epoch 2/25\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 0.6560 - categorical_accuracy: 0.7309 - val_loss: 0.7091 - val_categorical_accuracy: 0.7042\n",
      "Epoch 3/25\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 0.3556 - categorical_accuracy: 0.8683 - val_loss: 0.4776 - val_categorical_accuracy: 0.8081\n",
      "Epoch 4/25\n",
      "40/40 [==============================] - 1s 18ms/step - loss: 0.2376 - categorical_accuracy: 0.9157 - val_loss: 1.1215 - val_categorical_accuracy: 0.6514\n",
      "Test:\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6691 - categorical_accuracy: 0.7757\n",
      "------------------------------\n",
      "Epoch 1/25\n",
      "40/40 [==============================] - 2s 23ms/step - loss: 1.0239 - categorical_accuracy: 0.4776 - val_loss: 0.8914 - val_categorical_accuracy: 0.7905\n",
      "Epoch 2/25\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.6814 - categorical_accuracy: 0.7168 - val_loss: 0.6671 - val_categorical_accuracy: 0.7130\n",
      "Epoch 3/25\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.3700 - categorical_accuracy: 0.8609 - val_loss: 0.8595 - val_categorical_accuracy: 0.7025\n",
      "Test:\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5829 - categorical_accuracy: 0.7814\n",
      "------------------------------\n",
      "Epoch 1/25\n",
      "40/40 [==============================] - 2s 24ms/step - loss: 1.0323 - categorical_accuracy: 0.4558 - val_loss: 1.0473 - val_categorical_accuracy: 0.6743\n",
      "Epoch 2/25\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.6784 - categorical_accuracy: 0.7255 - val_loss: 0.6282 - val_categorical_accuracy: 0.7359\n",
      "Epoch 3/25\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.3701 - categorical_accuracy: 0.8636 - val_loss: 0.4655 - val_categorical_accuracy: 0.8046\n",
      "Epoch 4/25\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.2389 - categorical_accuracy: 0.9167 - val_loss: 0.6540 - val_categorical_accuracy: 0.7817\n",
      "Test:\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6293 - categorical_accuracy: 0.7729\n",
      "------------------------------\n",
      "Epoch 1/25\n",
      "40/40 [==============================] - 2s 24ms/step - loss: 1.0160 - categorical_accuracy: 0.4964 - val_loss: 0.8707 - val_categorical_accuracy: 0.8327\n",
      "Epoch 2/25\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.6337 - categorical_accuracy: 0.7476 - val_loss: 0.7246 - val_categorical_accuracy: 0.7394\n",
      "Epoch 3/25\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.3478 - categorical_accuracy: 0.8728 - val_loss: 0.7650 - val_categorical_accuracy: 0.7254\n",
      "Test:\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5733 - categorical_accuracy: 0.7736\n",
      "------------------------------\n",
      "Epoch 1/25\n",
      "40/40 [==============================] - 2s 26ms/step - loss: 1.0132 - categorical_accuracy: 0.4604 - val_loss: 0.8382 - val_categorical_accuracy: 0.7940\n",
      "Epoch 2/25\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.6904 - categorical_accuracy: 0.7277 - val_loss: 0.9102 - val_categorical_accuracy: 0.6426\n",
      "Test:\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6539 - categorical_accuracy: 0.7347\n",
      "------------------------------\n",
      "Average categorical accuracy: 0.7677\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "models = []\n",
    "kf = KFold(n_splits=5, shuffle=True) #make sure to shuffle, since I ordered based on label earlier\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    model = gen_model()\n",
    "    model.fit(x=X_train, y=Y_train, batch_size=128, validation_split=0.1, epochs=25, callbacks=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1))\n",
    "    print(\"Test:\")\n",
    "    results = model.evaluate(x=X_test, y=Y_test, batch_size=128)\n",
    "    print(\"------------------------------\")\n",
    "    all_results.append(results)\n",
    "    models.append(model)\n",
    "print(\"Average categorical accuracy: %.4f\" % (sum([r[1] for r in all_results])/len(all_results)))"
   ]
  },
  {
   "source": [
    "# Poking Around\n",
    "\n",
    "Let's take a random model from above and see some examples that it passed and failed on."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test loss: 0.6691 - Test Accuracy: 0.7757\n"
     ]
    }
   ],
   "source": [
    "model = models[0]\n",
    "print(\"Test loss: %.4f - Test Accuracy: %.4f\" % (all_results[0][0], all_results[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Got it right! positive\n",
      "['thank you so much for stepping up your game and making my day after night of elevator music much appreciated']\n",
      "\n",
      "Thought it was neutral, but it was positive.\n",
      "[\"“ jetblue our fleet's on fleek http t co 3kvkd8yrxa” lol wow\"]\n",
      "\n",
      "Thought it was negative, but it was positive.\n",
      "['thanks i actually made it my connection flight was delayed guess all delays are not a bad thing http t co xggcntco8m']\n",
      "\n",
      "Got it right! neutral\n",
      "['what said']\n",
      "\n",
      "Thought it was positive, but it was neutral.\n",
      "[\"i usually do but i didn't make the flight booking problems this time teach me yea i have that going for me at least haha\"]\n",
      "\n",
      "Thought it was negative, but it was neutral.\n",
      "['why why how many people even know what that means lol']\n",
      "\n",
      "Thought it was neutral, but it was negative.\n",
      "[\"it's really aggressive to entertainment in your faces amp they have little\"]\n",
      "\n",
      "Got it right! negative\n",
      "['this is the worst customer service i have ever had rebooked to tues but seat available on mon wtf contact me']\n",
      "\n",
      "Thought it was positive, but it was negative.\n",
      "[\"i can't wait for the and to find out how poorly handled this situation shameful http t co\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printed = [0]*9\n",
    "def itos(i):\n",
    "    arr = ['neutral', 'positive', 'negative']\n",
    "    return arr[i]\n",
    "\n",
    "for i in range(0, len(X), 128):\n",
    "    probs = model.predict(x=X[i:i+128])\n",
    "    for j in range(len(probs)):\n",
    "        pred = probs[j].argmax()\n",
    "        answer = Y[i+j].argmax()\n",
    "        index = pred*3 + answer\n",
    "        if printed[index]==0:\n",
    "            printed[index]=1\n",
    "            if pred!=answer:\n",
    "                print(f\"Thought it was {itos(pred)}, but it was {itos(answer)}.\")\n",
    "            else:\n",
    "                print(f\"Got it right! {itos(answer)}\")\n",
    "            print(tk.sequences_to_texts([X[i+j],])) \n",
    "            print()"
   ]
  },
  {
   "source": [
    "Some of these are quite short, and so very difficult. But you would think that we could correctly classify `u guys suck` as a negative... Probably not enough data to learn very good word embeddings. Using a pre-trained word embedding would probably be a lot more powerful."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}